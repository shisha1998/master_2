Описание проекта:

В рамках проекта необходимо поработать с реальными сырыми данными от одного из крупнейших маркетплейсов страны. Вас ждет интересная задача сопоставления и поиска наиболее похожих товаров. Сопоставление или “мэтчинг” (англ. matching - соответствия) - одна из базовых задач машинного обучения, которая встречается в информационном поиске, компьютерном зрении, рекомендательных системах и др.

Необходимо познакомиться с алгоритмами приближённого поиска ближайщих соседей, научиться создавать индексы в векторных базах данных и обучать ранжирующие модели. 

Задачи:

- разработать алгоритм, который для всех товаров из validation.csv предложит несколько вариантов наиболее похожих товаров из base;
- оценить качество алгоритма по метрике accuracy@5.



Были выгружены следующие данные:

- df_base (2918139 x 72) - анонимизированный набор товаров. Каждый товар представлен как уникальный id (0-base, 1-base, 2-base) и вектор признаков размерностью 72.
- df_train (1000000 x 72) - обучающий датасет. Каждая строчка - один товар, для которого известен уникальный id (0-query, 1-query, …) и вектор признаков размерностью 72. 
- targets - id товара из base.csv, который максимально похож на вектор обучающего датасета (по мнению экспертов).
- df_validation (1000000 x 72) - валидационный датасет с товарами (уникальный id и вектор признаков размерностью 72).
- df_validation_answer - правильные ответы валидационного датасеты.



Данные были проанализированы и предобработаны:

В данных базового датасета не было найдено пропусков и дубликатов. В основном признаки базового датасета имеют нормальное распределение, кроме признаков '6', '21', '25', '33', '44', '59', '65', '70'. Данные признаки были удалены из базового, обучающего и валидационного датасета, что привело к увеличению метрики с 63 до 70 процентов. Также данные базового, обучающего и валидационного датасета были отмасштабированы при помощи StandardScaler().



Была разработана модель с использованием FAISS:

Был создан idx_l2 или пространство векторов размерностью dims = 72, разделяемое на n_cells = 1708 кластеров (количество кластеров равно корню из количества векторов в базовом датасете) с помощью quantizer (квантователь: нужен для присвоения векторов определенному кластеру, использует метрику расстояния L2). 

idx_l2 был сначала обучен для создания 1708 кластеров, а затем векторы были добавлены к этим кластерам. 

Был настроен параметр nprobe, который указывает количество кластеров, которые необходимо посетить во время операции поиска.

Был выполнен поиск по idx_l2 5 похожих векторов для обучающего датасета, в итоге было получено Accuracy@5 для обучающего датасета равное 70.179.

Был выполнен поиск по idx_l2 5 похожих векторов для валидационного датасета, в итоге было получено Accuracy@5 для валидационного датасета равное 70.179.



Была разработана модель с использованием FAISS и CatBoostClassifier:

Выполним поиск по idx_l2 50 похожих векторов для обучающего и валидационного датасета. При помощи найденных 50 векторов был создан датасет для обучения CatBoostClassifier и датасет для последующих предсказаний, состоящих из векторов двойной длины (каждому вектору обучающей или валидационной выборки соответсвует 50 найденных векторов из базового датасета), а также был создан столбец таргетов для обучающего датасета (если индексы базового датасета и обучающего совпадают, то 1, иначе 0).

Было установлено, что в данных для обучения CatBoostClassifier имеется сильный дисбаланс классов.

Был создан пайплайн, включающий StandardScaler() для масштабирования данных и CatBoostClassifier() с параметрами: время обучения = 0.2 и глубина = 6. Данная модель была обучена и были получены вероятности того, что объект принадлежит к заданным классам (0 или 1).

Были отсортированы первые пять самых больших вероятностей, по которым было посчитано Accuracy@5 для модели FAISS + CatBoostClassifier. Accuracy@5 для модели FAISS + CatBoostClassifier равняется 68.174. Данное значение меньше Accuracy@5 только для модели FAISS. Использование CatBoostClassifier прибавки к метрике не дало.